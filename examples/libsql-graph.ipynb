{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.pardir))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from libsql_graph_db import database as db\n",
    "from dotenv import load_dotenv # type: ignore\n",
    "\n",
    "load_dotenv()\n",
    "db_url = os.getenv(\"LIBSQL_URL\")\n",
    "auth_token = os.getenv(\"LIBSQL_AUTH_TOKEN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/anubhuti/Desktop/simple-graph-db/libsql_graph_db/database.py\", line 81, in initialize\n",
      "thread '<unnamed>' panicked at /root/.cargo/registry/src/index.crates.io-6f17d22bba15001f/libsql-0.3.1/src/hrana/hyper.rs:88:9:\n",
      "there is no reactor running, must be called from the context of a Tokio 1.x runtime\n",
      "note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\n",
      "    return atomic(_init, db_url, auth_token)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "pyo3_runtime.PanicException: there is no reactor running, must be called from the context of a Tokio 1.x runtime\n"
     ]
    }
   ],
   "source": [
    "# To initialze the database and establish a connection with tursodb\n",
    "db.initialize(db_url, auth_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(53, 'Diabetes Symptoms', '{\"body\":\"Continuos urination\",\"type\":[\"person\",\"patient\"],\"id\":1}', '1', '2024-04-05 04:51:21', '2024-04-05 04:51:21')]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Hrana: `cursor error: `error at step 0: (error code: SQLITE_UNKNOWN) `SQLite error: Limit must be greater than 0, got 0```",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSymptom\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mfind_nodes_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m, in \u001b[0;36mfind_nodes_like\u001b[0;34m(db_url, auth_token, label, threshold)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_nodes_like\u001b[39m(db_url, auth_token, label, threshold):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matomic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_similar_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth_token\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/simple-graph-db/libsql_graph_db/database.py:64\u001b[0m, in \u001b[0;36matomic\u001b[0;34m(cursor_exec_fn, db_url, auth_token)\u001b[0m\n\u001b[1;32m     62\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcursor()\n\u001b[1;32m     63\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPRAGMA foreign_keys = TRUE;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 64\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mcursor_exec_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     connection\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/simple-graph-db/libsql_graph_db/database.py:746\u001b[0m, in \u001b[0;36mfind_similar_nodes.<locals>._identical_nodes\u001b[0;34m(cursor, connection)\u001b[0m\n\u001b[1;32m    744\u001b[0m similar_rows \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes:\n\u001b[0;32m--> 746\u001b[0m     similar_nodes \u001b[38;5;241m=\u001b[39m \u001b[43mvector_search_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m similar_nodes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    749\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/simple-graph-db/libsql_graph_db/database.py:138\u001b[0m, in \u001b[0;36mvector_search_node.<locals>._search_node\u001b[0;34m(cursor, connection)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvector-search-node.sql\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m--> 138\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetchall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    141\u001b[0m         filtered_results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    142\u001b[0m             (node[\u001b[38;5;241m0\u001b[39m], node[\u001b[38;5;241m4\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes \u001b[38;5;28;01mif\u001b[39;00m node[\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m<\u001b[39m threshold\n\u001b[1;32m    143\u001b[0m         ]\n",
      "\u001b[0;31mValueError\u001b[0m: Hrana: `cursor error: `error at step 0: (error code: SQLITE_UNKNOWN) `SQLite error: Limit must be greater than 0, got 0```"
     ]
    }
   ],
   "source": [
    "# find nodes like\n",
    "def find_nodes_like(db_url, auth_token, label, threshold):\n",
    "    return db.atomic(db.find_similar_nodes(label, threshold), db_url, auth_token)\n",
    "\n",
    "label = \"Symptoms\"\n",
    "threshold = 0.9\n",
    "find_nodes_like(db_url, auth_token, label, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge by similarity\n",
    "\n",
    "def merge_nodes(threshold, k ,db_url, auth_token):\n",
    "    db.atomic(db.pruning(threshold, k), db_url, auth_token)\n",
    "    \n",
    "threshold = 0.9\n",
    "k = 2\n",
    "merge_nodes(threshold, k, db_url, auth_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add a single node\n",
    "def insert_single_node(db_url, auth_token, new_label, new_node, new_node_id):\n",
    "    try:\n",
    "        db.atomic(db.add_node(new_label, new_node, new_node_id), db_url, auth_token)\n",
    "    except Exception as e:\n",
    "        assert False\n",
    "new_node = {'body': 'Continuos urination', 'type': ['person', 'patient']}\n",
    "new_label = \"Diabetes Symptoms\"\n",
    "new_node_id = 1\n",
    "\n",
    "insert_single_node(db_url, auth_token, new_label, new_node, new_node_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add multiple nodes\n",
    "def bulk_insert_operations(db_url, auth_token, labels, nodes):\n",
    "    ids = []\n",
    "    bodies = []\n",
    "    for id, body in nodes.items():\n",
    "        ids.append(id)\n",
    "        bodies.append(body)\n",
    "\n",
    "    # bulk add and confirm\n",
    "    db.atomic(db.add_nodes(bodies, labels, ids), db_url, auth_token)\n",
    "\n",
    "new_nodes = {\n",
    "    3 : {'name': 'Peri', 'age': '90'},\n",
    "    4: {'name': 'Pema', 'age': '66'},\n",
    "    5: {'name': \"Ella\", 'age': '45'}\n",
    "}\n",
    "new_labels = [\"Retired Doctor\", \"Tuberculosis Patient\", \"Diabetes Pateint\"]\n",
    "\n",
    "bulk_insert_operations(db_url, auth_token, new_labels, new_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find for a node\n",
    "def find_a_node(db_url, auth_token, node):\n",
    "            return db.atomic(db.find_node(node), db_url, auth_token)\n",
    "\n",
    "\n",
    "find_a_node(db_url, auth_token, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For bulk upsert: Update and insert\n",
    "def bulk_upsert(db_url, auth_token, labels, nodes):\n",
    "    ids = []\n",
    "    bodies = []\n",
    "    for id, body in nodes.items():\n",
    "        ids.append(id)\n",
    "        bodies.append(body)\n",
    "\n",
    "    db.atomic(db.upsert_nodes(bodies, labels, ids), db_url, auth_token)\n",
    "nodes = {\n",
    "    1 : {'name': 'Stanley', 'age': '30'},\n",
    "    \n",
    "    2 : {'name': 'Sheeran', 'type': ['singer', 'rich']}\n",
    "}\n",
    "labels = [\"Lunch Box\", \"Pop Singer\"]\n",
    "\n",
    "bulk_upsert(db_url, auth_token, labels, nodes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For single upsert: Update and insert a node\n",
    "def single_upsert(db_url, auth_token, label, body, id):\n",
    "    \n",
    "    db.atomic(db.upsert_node(id, label, body), db_url, auth_token)\n",
    "\n",
    "body = {'name': 'Sheeran', 'type': ['singer', 'rich']}\n",
    "label = \"related as an\"\n",
    "id = 2\n",
    "single_upsert(db_url, auth_token, label, body, id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bulk connect and confirm\n",
    "def bulk_node_connect(db_url, auth_token, labels, edges):\n",
    "    sources = []\n",
    "    targets = []\n",
    "    attributes = []\n",
    "    for src, tgts in edges.items():\n",
    "        for target in tgts:\n",
    "            tgt, label = target\n",
    "            sources.append(src)\n",
    "            targets.append(tgt)\n",
    "            if label:\n",
    "                attributes.append(label)\n",
    "            else:\n",
    "                attributes.append({})\n",
    "        \n",
    "\n",
    "    db.atomic(db.connect_many_nodes(\n",
    "        sources, targets, label, attributes), db_url, auth_token)\n",
    "    \n",
    "edges = {\n",
    "    2: [\n",
    "        (3 , {'disease':'Diabetes'}),\n",
    "        (1 , {'patient': 'Diabetes Symptoms'})\n",
    "    ]\n",
    "}\n",
    "edges_labels = [\"Has\", \"is\"]\n",
    "\n",
    "bulk_node_connect(db_url, auth_token, edges_labels, edges)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single connect and confirm\n",
    "def single_node_connect(db_url, auth_token, source, target, label, attribute):\n",
    "    db.atomic(db.connect_nodes(\n",
    "        source, target,  label, attribute), db_url, auth_token)\n",
    "    \n",
    "source = 3\n",
    "target = 1\n",
    "label = \"treats\"\n",
    "attribute = {\"person\": \"old man\", \"disease\": \"Asthma\"}\n",
    "\n",
    "single_node_connect(db_url, auth_token, source, target, label, attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove nodes\n",
    "def remove_bulk_nodes(db_url, auth_token, ids):\n",
    "        db.atomic(db.remove_nodes(ids), db_url, auth_token)\n",
    "\n",
    "ids = [1, 4]\n",
    "\n",
    "remove_bulk_nodes(db_url, auth_token, ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove a single node\n",
    "def remove_single_node(db_url, auth_token, id):\n",
    "    db.atomic(db.remove_node(id), db_url, auth_token)\n",
    "\n",
    "remove_single_node(db_url, auth_token, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To traverse the nodes\n",
    "def traverse_nodes(db_url, auth_token, src, tgt):\n",
    "    return db.traverse(db_url, auth_token, src, tgt)\n",
    "traverse_nodes(db_url, auth_token, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To generate a query clause and find nodes\n",
    "kv_name_like = db._generate_clause('name', predicate='LIKE')\n",
    "print(db.atomic(db.find_nodes([kv_name_like], ('Pe%',)), db_url, auth_token))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "from libsql_graph_db import visualizers\n",
    "raw_path = \"temp_path\" +  \"sample1.dot\"\n",
    "visualizers.graphviz_visualize(db_url, auth_token, raw_path, ['2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization with bodies\n",
    "\n",
    "raw_path = \"temp_path\" +  \"bodies.dot\"\n",
    "path_with_bodies = db.traverse(db_url, auth_token, 2, with_bodies=True)\n",
    "visualizers.graphviz_visualize_bodies(raw_path, path_with_bodies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector search node\n",
    "def vector_search_node(db_url, auth_token, data, k):\n",
    "    try:\n",
    "        db.atomic(db.vector_search_node(data, k), db_url, auth_token)\n",
    "    except Exception as e:\n",
    "        assert False\n",
    "        \n",
    "data = {\"patient\": \"has diabetes\"}\n",
    "k = 1\n",
    "vector_search_node(db_url, auth_token, data, k)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector search edge\n",
    "def vector_search_edge(db_url, auth_token, data, k):\n",
    "    try:\n",
    "        db.atomic(db.vector_search_edge(data, k), db_url, auth_token)\n",
    "    except Exception as e:\n",
    "        assert False\n",
    "        \n",
    "data = {'subject': 'MES', 'type': ['person', 'Dr']}\n",
    "k = 1\n",
    "vector_search_edge(db_url, auth_token, data, k)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simple-graph-sqlite-_HGANDYB-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
